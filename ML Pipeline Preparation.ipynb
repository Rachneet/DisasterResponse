{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rachneet/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rachneet/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/rachneet/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "# nlp libraries\n",
    "import nltk\n",
    "nltk.download(['punkt', 'stopwords', 'wordnet'])\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# ml libraries\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, recall_score, precision_score\n",
    "from sklearn.multioutput import MultiOutputClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikit-learn --upgrade\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterResponse.db')\n",
    "df = pd.read_sql('DisasterResponse.db', engine)\n",
    "X = df['message'].values\n",
    "Y = df.drop(['id', 'message', 'original', 'genre'], axis=1).values\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, message, original, genre, related, request, offer, aid_related, medical_help, medical_products, search_and_rescue, security, military, child_alone, water, food, shelter, clothing, money, missing_people, refugees, death, other_aid, infrastructure_related, transport, buildings, electricity, tools, hospitals, shops, aid_centers, other_infrastructure, weather_related, floods, storm, fire, earthquake, cold, other_weather, direct_report]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.aid_related==2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contractions import contractions_dict\n",
    "\n",
    "def expand_contractions(text, contractions_dict):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "    \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "\n",
    "def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contractions_dict.get(match) \\\n",
    "            if contractions_dict.get(match) \\\n",
    "            else contractions_dict.get(match.lower())\n",
    "        expanded_contraction = expanded_contraction\n",
    "        return expanded_contraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    Args:\n",
    "        text(string): a string containing the message\n",
    "    Return:\n",
    "        tokenized_message(list): a list of words containing the processed message\n",
    "\n",
    "    '''\n",
    "    tokenized_message = []\n",
    "    try:\n",
    "        \n",
    "        # for unbalanced parenthesis problem\n",
    "        text = text.replace(')','')\n",
    "        text = text.replace('(','')\n",
    "        \n",
    "        url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "        \n",
    "         # get list of all urls using regex\n",
    "        detected_urls = re.findall(url_regex, text)\n",
    "        \n",
    "        # replace each url in text string with placeholder\n",
    "        for url in detected_urls:\n",
    "            text = re.sub(url, \"urlplaceholder\", text)\n",
    "\n",
    "        # remove whitespaces\n",
    "        text = re.sub(r\" +\", \" \", text)\n",
    "        \n",
    "        # expand contractions\n",
    "        text = expand_contractions(text, contractions_dict)\n",
    "\n",
    "        # tokenize text\n",
    "        tokens = word_tokenize(text)\n",
    "       \n",
    "        # initiate lemmatizer\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        # get stopwords\n",
    "        stopwords_english = stopwords.words('english')\n",
    "        stopwords_english += 'u'\n",
    "\n",
    "        for word in tokens:\n",
    "            # normalize word\n",
    "            word = word.lower()\n",
    "          \n",
    "            if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "                \n",
    "                word = lemmatizer.lemmatize(word)  # lemmatizing word\n",
    "                tokenized_message.append(word)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "#         print(text)\n",
    "        \n",
    "    return tokenized_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'time', 'see', 'second', 'renaissance', 'may', 'look', 'boring', 'look', 'least', 'twice', 'definitely', 'watch', 'part', '2', 'change', 'view', 'matrix', 'human', 'people', 'one', 'urlplaceholder', 'started', 'war', 'ai', 'bad', 'thing']\n"
     ]
    }
   ],
   "source": [
    "text = \"The first time you   see The Second Renaissance it may   look boring. Look at it at least twice and definitely watch part 2. It will change your view of the matrix. Are the human people the ones https://bachda.com)  who started the war ? Is AI a bad thing ?\"\n",
    "print(tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi output classifier\n",
    "pipeline_multi = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(n_jobs=10)))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:62.05896782875061\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=4)\n",
    "pipeline_multi.fit(X_train, y_train)\n",
    "end = time()\n",
    "\n",
    "print(\"Training time:{}\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_multi.predict(X_test)\n",
    "report = []\n",
    "for idx, col in enumerate(y_pred.T):\n",
    "    report.append(f1_score(y_test.T[idx], col, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rachneet/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "full_report = []\n",
    "for idx, col in enumerate(y_pred.T):\n",
    "    full_report.append(classification_report(y_test.T[idx], col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8030172581621196, 0.8889930969213857, 0.9917124722746894, 0.7786338971674004, 0.9038678741959928, 0.9369072804110671, 0.9609627922494944, 0.9718597584401955, 0.9500228109988827, 1.0, 0.9473010789661409, 0.9387282095617763, 0.9242893395900669, 0.9770436829909154, 0.9691966670769512, 0.9836900874854219, 0.9493531561502692, 0.9538228729096186, 0.8201524540975088, 0.9123017873618181, 0.9412920741602253, 0.9422969143189367, 0.9728452539713291, 0.9922835323617831, 0.9834403633829247, 0.9925690898928685, 0.9814459719245847, 0.9445668168570569, 0.8743640983114663, 0.9408875264511519, 0.9327767450195307, 0.9823842130916282, 0.9726861292412279, 0.9725205543430628, 0.9285204600684861, 0.8370026862463706]\n",
      "0.9376038612959542\n"
     ]
    }
   ],
   "source": [
    "print(report)\n",
    "print(np.mean(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.40      0.52      1238\n",
      "           1       0.84      0.95      0.89      4006\n",
      "\n",
      "    accuracy                           0.82      5244\n",
      "   macro avg       0.78      0.68      0.70      5244\n",
      "weighted avg       0.81      0.82      0.80      5244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(full_report[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': ((1,1), (1,2)),\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__n_estimators': [100, 200, 300],\n",
    "    'clf__min_samples_split': [2, 3, 4],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline_multi, param_grid=parameters, n_jobs=10, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rachneet/anaconda3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x7f1d9fbbcbf8>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf', RandomForestClassifier())]),\n",
       "             n_jobs=10,\n",
       "             param_grid={'clf__min_samples_split': [2, 3, 4],\n",
       "                         'clf__n_estimators': [100, 200, 300],\n",
       "                         'tfidf__use_idf': (True, False),\n",
       "                         'vect__max_df': (0.5, 0.75, 1.0),\n",
       "                         'vect__max_features': (None, 5000, 10000),\n",
       "                         'vect__ngram_range': ((1, 1), (1, 2))})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_params.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(cv, \"best_params.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__min_samples_split': 2,\n",
       " 'clf__n_estimators': 100,\n",
       " 'tfidf__use_idf': False,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': 5000,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with best params\n",
    "# multi output classifier\n",
    "pipeline_multi_best = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize, max_df=0.5, max_features=5000, ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(n_estimators=100, min_samples_split=2, n_jobs=10)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:47.22592377662659\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "pipeline_multi_best.fit(X_train, y_train)\n",
    "end = time()\n",
    "\n",
    "print(\"Training time:{}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_multi_best.predict(X_test)\n",
    "report = []\n",
    "for idx, col in enumerate(y_pred.T):\n",
    "    report.append(f1_score(y_test.T[idx], col, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80826145170927, 0.8839689542463472, 0.9917124722746894, 0.7739841853976814, 0.9043479337286663, 0.947266174588642, 0.965884411896301, 0.9736646879100621, 0.9559498484153882, 1.0, 0.9586550302483187, 0.9479940879403576, 0.9350153975990199, 0.9816585517191361, 0.9665131609339072, 0.9780519218494087, 0.9540567997208698, 0.9515079610756865, 0.8194629236133815, 0.9009293106489187, 0.9420527135590082, 0.9421775783331847, 0.9729654932210757, 0.9891436100131752, 0.9828704447364472, 0.994854209149384, 0.9823006000810917, 0.931509206100485, 0.8786325645865102, 0.9495559046587569, 0.9437514842008289, 0.9853017181560437, 0.971446950540802, 0.9746307332171688, 0.9309944311226099, 0.8332650295154341]\n",
      "0.9390093871307794\n"
     ]
    }
   ],
   "source": [
    "print(report)\n",
    "print(np.mean(report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new tranformers for features\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            if pos_tags:\n",
    "                first_word, first_tag = pos_tags[0][0], pos_tags[0][1]\n",
    "                if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                    return True\n",
    "        return False\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        x_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(x_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_improved = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        \n",
    "        ('nlp_pipeline', Pipeline([\n",
    "            ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        \n",
    "        ('starting_verb', StartingVerbExtractor())\n",
    "    ])),\n",
    "    \n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier(n_jobs=10)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 21s ± 126 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pipeline_improved.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8 s ± 258 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "0.9374718642268118\n"
     ]
    }
   ],
   "source": [
    "%timeit pred = pipeline_improved.predict(X_test)\n",
    "report = []\n",
    "for idx, col in enumerate(pred.T):\n",
    "    report.append(f1_score(y_test.T[idx], col, average='weighted'))\n",
    "print(np.mean(report))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost for better perfromance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(xgb.sklearn.XGBClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=4)\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 75.94581055641174\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9399919814415109\n"
     ]
    }
   ],
   "source": [
    "pred = pipeline_xgb.predict(X_test)\n",
    "report = []\n",
    "for idx, col in enumerate(pred.T):\n",
    "    report.append(f1_score(y_test.T[idx], col, average='weighted'))\n",
    "print(np.mean(report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rachneet/anaconda3/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "c_report = []\n",
    "# for idx, col in enumerate(pred):\n",
    "#     c_report.append(classification_report(y_test[:idx], pred[:idx], labels=df.columns[4:].tolist()))\n",
    "cols = df.columns[4:].tolist()\n",
    "\n",
    "for idx in range(pred.shape[1]):\n",
    "    c_report.append(classification_report(y_test[:, idx],pred[:, idx], output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9399919814415109\n"
     ]
    }
   ],
   "source": [
    "f1= []\n",
    "for i in range(len(c_report)):\n",
    "    f1.append(c_report[i]['weighted avg']['f1-score'])\n",
    "print(np.mean(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oprimize xgboost parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "#     'vect__ngram_range': ((1,1), (1,2)),\n",
    "#     'vect__max_df': (0.5, 0.75, 1.0),\n",
    "#     'vect__max_features': (None, 5000, 10000),\n",
    "#     'tfidf__use_idf': (True, False),\n",
    "    'clf__estimator__learning_rate': [0.05, 0.15, 0.25],  # shrinks feature values for better boosting\n",
    "    'clf__estimator__max_depth': [4, 6, 8, 10],\n",
    "    'clf__estimator__min_child_weight': [1, 3, 5, 7],   # sum of child weights for further partitioning\n",
    "    'clf__estimator__gamma': [0.0, 0.1, 0.2, 0.3, 0.4],  # prevents overfitting, split leaf node if min. gamma loss\n",
    "    'clf__estimator__colsample_bytree': [0.3, 0.4, 0.5, 0.7]  # subsample ratio of columns when tree is constructed\n",
    "}\n",
    "\n",
    "xgb_cv = GridSearchCV(pipeline_xgb, param_grid=parameters, n_jobs=10, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=10)]: Done  41 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=10)]: Done  52 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=10)]: Done  65 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=10)]: Done  78 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=10)]: Done  93 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=10)]: Done 108 tasks      | elapsed: 15.8min\n",
      "[Parallel(n_jobs=10)]: Done 125 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=10)]: Done 142 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=10)]: Done 161 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed: 25.9min\n",
      "[Parallel(n_jobs=10)]: Done 201 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=10)]: Done 222 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=10)]: Done 245 tasks      | elapsed: 35.6min\n",
      "[Parallel(n_jobs=10)]: Done 268 tasks      | elapsed: 38.2min\n",
      "[Parallel(n_jobs=10)]: Done 293 tasks      | elapsed: 42.3min\n",
      "[Parallel(n_jobs=10)]: Done 318 tasks      | elapsed: 46.9min\n",
      "[Parallel(n_jobs=10)]: Done 345 tasks      | elapsed: 50.1min\n",
      "[Parallel(n_jobs=10)]: Done 372 tasks      | elapsed: 53.9min\n",
      "[Parallel(n_jobs=10)]: Done 401 tasks      | elapsed: 58.6min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 61.6min\n",
      "[Parallel(n_jobs=10)]: Done 461 tasks      | elapsed: 66.3min\n",
      "[Parallel(n_jobs=10)]: Done 492 tasks      | elapsed: 70.6min\n",
      "[Parallel(n_jobs=10)]: Done 525 tasks      | elapsed: 75.8min\n",
      "[Parallel(n_jobs=10)]: Done 558 tasks      | elapsed: 81.3min\n",
      "[Parallel(n_jobs=10)]: Done 593 tasks      | elapsed: 85.3min\n",
      "[Parallel(n_jobs=10)]: Done 628 tasks      | elapsed: 91.1min\n",
      "[Parallel(n_jobs=10)]: Done 665 tasks      | elapsed: 95.5min\n",
      "[Parallel(n_jobs=10)]: Done 702 tasks      | elapsed: 101.4min\n",
      "[Parallel(n_jobs=10)]: Done 741 tasks      | elapsed: 106.4min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 112.1min\n",
      "[Parallel(n_jobs=10)]: Done 821 tasks      | elapsed: 118.3min\n",
      "[Parallel(n_jobs=10)]: Done 862 tasks      | elapsed: 124.6min\n",
      "[Parallel(n_jobs=10)]: Done 905 tasks      | elapsed: 130.0min\n",
      "[Parallel(n_jobs=10)]: Done 948 tasks      | elapsed: 136.4min\n",
      "[Parallel(n_jobs=10)]: Done 993 tasks      | elapsed: 142.3min\n",
      "[Parallel(n_jobs=10)]: Done 1038 tasks      | elapsed: 150.3min\n",
      "[Parallel(n_jobs=10)]: Done 1085 tasks      | elapsed: 156.0min\n",
      "[Parallel(n_jobs=10)]: Done 1132 tasks      | elapsed: 162.8min\n",
      "[Parallel(n_jobs=10)]: Done 1181 tasks      | elapsed: 169.7min\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed: 177.1min\n",
      "[Parallel(n_jobs=10)]: Done 1281 tasks      | elapsed: 187.9min\n",
      "[Parallel(n_jobs=10)]: Done 1332 tasks      | elapsed: 195.7min\n",
      "[Parallel(n_jobs=10)]: Done 1385 tasks      | elapsed: 204.7min\n",
      "[Parallel(n_jobs=10)]: Done 1438 tasks      | elapsed: 214.6min\n",
      "[Parallel(n_jobs=10)]: Done 1493 tasks      | elapsed: 224.3min\n",
      "[Parallel(n_jobs=10)]: Done 1548 tasks      | elapsed: 233.5min\n",
      "[Parallel(n_jobs=10)]: Done 1605 tasks      | elapsed: 244.1min\n",
      "[Parallel(n_jobs=10)]: Done 1662 tasks      | elapsed: 253.7min\n",
      "[Parallel(n_jobs=10)]: Done 1721 tasks      | elapsed: 263.5min\n",
      "[Parallel(n_jobs=10)]: Done 1780 tasks      | elapsed: 274.2min\n",
      "[Parallel(n_jobs=10)]: Done 1841 tasks      | elapsed: 285.9min\n",
      "[Parallel(n_jobs=10)]: Done 1902 tasks      | elapsed: 296.2min\n",
      "[Parallel(n_jobs=10)]: Done 1965 tasks      | elapsed: 306.4min\n",
      "[Parallel(n_jobs=10)]: Done 2028 tasks      | elapsed: 317.7min\n",
      "[Parallel(n_jobs=10)]: Done 2093 tasks      | elapsed: 329.3min\n",
      "[Parallel(n_jobs=10)]: Done 2158 tasks      | elapsed: 341.2min\n",
      "[Parallel(n_jobs=10)]: Done 2225 tasks      | elapsed: 353.5min\n",
      "[Parallel(n_jobs=10)]: Done 2292 tasks      | elapsed: 364.2min\n",
      "[Parallel(n_jobs=10)]: Done 2361 tasks      | elapsed: 375.8min\n",
      "[Parallel(n_jobs=10)]: Done 2430 tasks      | elapsed: 388.3min\n",
      "[Parallel(n_jobs=10)]: Done 2501 tasks      | elapsed: 404.0min\n",
      "[Parallel(n_jobs=10)]: Done 2572 tasks      | elapsed: 419.1min\n",
      "[Parallel(n_jobs=10)]: Done 2645 tasks      | elapsed: 434.1min\n",
      "[Parallel(n_jobs=10)]: Done 2718 tasks      | elapsed: 450.8min\n",
      "[Parallel(n_jobs=10)]: Done 2793 tasks      | elapsed: 465.3min\n",
      "[Parallel(n_jobs=10)]: Done 2868 tasks      | elapsed: 480.8min\n",
      "[Parallel(n_jobs=10)]: Done 2945 tasks      | elapsed: 497.7min\n",
      "[Parallel(n_jobs=10)]: Done 3022 tasks      | elapsed: 513.4min\n",
      "[Parallel(n_jobs=10)]: Done 3101 tasks      | elapsed: 528.5min\n",
      "[Parallel(n_jobs=10)]: Done 3180 tasks      | elapsed: 545.2min\n",
      "[Parallel(n_jobs=10)]: Done 3261 tasks      | elapsed: 563.0min\n",
      "[Parallel(n_jobs=10)]: Done 3342 tasks      | elapsed: 579.0min\n",
      "[Parallel(n_jobs=10)]: Done 3425 tasks      | elapsed: 597.2min\n",
      "[Parallel(n_jobs=10)]: Done 3508 tasks      | elapsed: 614.1min\n",
      "[Parallel(n_jobs=10)]: Done 3593 tasks      | elapsed: 631.5min\n",
      "[Parallel(n_jobs=10)]: Done 3678 tasks      | elapsed: 655.7min\n",
      "[Parallel(n_jobs=10)]: Done 3765 tasks      | elapsed: 678.3min\n",
      "[Parallel(n_jobs=10)]: Done 3852 tasks      | elapsed: 699.9min\n",
      "[Parallel(n_jobs=10)]: Done 3941 tasks      | elapsed: 724.8min\n",
      "[Parallel(n_jobs=10)]: Done 4030 tasks      | elapsed: 748.1min\n",
      "[Parallel(n_jobs=10)]: Done 4121 tasks      | elapsed: 773.3min\n",
      "[Parallel(n_jobs=10)]: Done 4212 tasks      | elapsed: 797.8min\n",
      "[Parallel(n_jobs=10)]: Done 4305 tasks      | elapsed: 824.7min\n",
      "[Parallel(n_jobs=10)]: Done 4398 tasks      | elapsed: 851.2min\n",
      "[Parallel(n_jobs=10)]: Done 4493 tasks      | elapsed: 875.0min\n",
      "[Parallel(n_jobs=10)]: Done 4588 tasks      | elapsed: 900.1min\n",
      "[Parallel(n_jobs=10)]: Done 4685 tasks      | elapsed: 927.5min\n",
      "[Parallel(n_jobs=10)]: Done 4800 out of 4800 | elapsed: 958.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgb_params.pkl']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv.fit(X_train, y_train)\n",
    "joblib.dump(xgb_cv, 'xgb_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__colsample_bytree': 0.7,\n",
       " 'clf__estimator__gamma': 0.4,\n",
       " 'clf__estimator__learning_rate': 0.25,\n",
       " 'clf__estimator__max_depth': 10,\n",
       " 'clf__estimator__min_child_weight': 7}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29587037046510056"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 124.384770154953\n",
      "Mean fi-score: 0.9455706541768107\n"
     ]
    }
   ],
   "source": [
    "pipeline_xgb = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(xgb.sklearn.XGBClassifier(colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=10, min_child_weight=7)))\n",
    "])\n",
    "\n",
    "start = time()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=4)\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "end = time()\n",
    "\n",
    "print(\"Training Time: {}\".format(end-start))\n",
    "\n",
    "pred = pipeline_xgb.predict(X_test)\n",
    "report = []\n",
    "for idx, col in enumerate(pred.T):\n",
    "    report.append(f1_score(y_test.T[idx], col, average='weighted'))\n",
    "print(\"Mean f1-score: {}\".format(np.mean(report)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 14.5min\n",
      "[Parallel(n_jobs=10)]: Done  41 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=10)]: Done  52 tasks      | elapsed: 23.7min\n",
      "/home/rachneet/anaconda3/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=10)]: Done  65 tasks      | elapsed: 29.6min\n",
      "[Parallel(n_jobs=10)]: Done  78 tasks      | elapsed: 35.3min\n",
      "[Parallel(n_jobs=10)]: Done  93 tasks      | elapsed: 42.0min\n",
      "[Parallel(n_jobs=10)]: Done 108 tasks      | elapsed: 48.6min\n",
      "[Parallel(n_jobs=10)]: Done 125 tasks      | elapsed: 56.6min\n",
      "[Parallel(n_jobs=10)]: Done 142 tasks      | elapsed: 64.5min\n",
      "[Parallel(n_jobs=10)]: Done 161 tasks      | elapsed: 72.1min\n",
      "[Parallel(n_jobs=10)]: Done 180 out of 180 | elapsed: 80.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 out of 180 | elapsed: 80.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vect_params.pkl']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': ((1,1), (1,2)),\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000),\n",
    "    'tfidf__use_idf': (True, False)\n",
    "#     'clf__estimator__learning_rate': [0.05, 0.15, 0.25],  # shrinks feature values for better boosting\n",
    "#     'clf__estimator__max_depth': [4, 6, 8, 10],\n",
    "#     'clf__estimator__min_child_weight': [1, 3, 5, 7],   # sum of child weights for further partitioning\n",
    "#     'clf__estimator__gamma': [0.0, 0.1, 0.2, 0.3, 0.4],  # prevents overfitting, split leaf node if min. gamma loss\n",
    "#     'clf__estimator__colsample_bytree': [0.3, 0.4, 0.5, 0.7]  # subsample ratio of columns when tree is constructed\n",
    "}\n",
    "\n",
    "vect_cv = GridSearchCV(pipeline_xgb, param_grid=parameters, n_jobs=10, verbose=10)\n",
    "\n",
    "vect_cv.fit(X_train, y_train)\n",
    "joblib.dump(vect_cv, 'vect_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__use_idf': False,\n",
       " 'vect__max_df': 0.5,\n",
       " 'vect__max_features': None,\n",
       " 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3023075362215049"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 428.9596199989319\n",
      "Mean f1-score: 0.9459521628170968\n"
     ]
    }
   ],
   "source": [
    "pipeline_xgb = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer=tokenize, max_df=0.5, max_features=None, ngram_range=(1,2))),\n",
    "    ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "    ('clf', MultiOutputClassifier(xgb.sklearn.XGBClassifier(colsample_bytree=0.7, gamma=0.4, learning_rate=0.25, max_depth=10, min_child_weight=7)))\n",
    "])\n",
    "\n",
    "start = time()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=4)\n",
    "pipeline_xgb.fit(X_train, y_train)\n",
    "end = time()\n",
    "\n",
    "print(\"Training Time: {}\".format(end-start))\n",
    "\n",
    "pred = pipeline_xgb.predict(X_test)\n",
    "report = []\n",
    "for idx, col in enumerate(pred.T):\n",
    "    report.append(f1_score(y_test.T[idx], col, average='weighted'))\n",
    "print(\"Mean f1-score: {}\".format(np.mean(report)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipeline_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/xgboost_model.pkl']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline_xgb, 'models/xgboost_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
